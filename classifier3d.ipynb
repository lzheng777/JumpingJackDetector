{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "classifier3d.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6APFQh7AEA0"
      },
      "source": [
        "!wget https://storage.googleapis.com/deepmind-media/Datasets/kinetics600.tar.gz\n",
        "!tar -xvf /content/kinetics600.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5STGG2_9EtM1"
      },
      "source": [
        "!pip install pytube"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6tf0P0-a3JR",
        "outputId": "da1f922e-e94a-4ca0-caf0-b3f445f1f83a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_vZaJvMeD3y"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms, models\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import cv2\n",
        "from imutils import paths\n",
        "import albumentations as album\n",
        "import glob\n",
        "import random\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RB5sNQNfxHc",
        "outputId": "9c7712d3-2d20-4cbf-d869-a21ac0853e33"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda:0')\n",
        "else:\n",
        "  device = torch.device('cpu')\n",
        "  \n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlDjkTzpBeM-"
      },
      "source": [
        "train_set = pd.read_csv('/content/kinetics600/train.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYFKQsieErBA"
      },
      "source": [
        "from pytube import YouTube\n",
        "\n",
        "youtube_video_url = 'https://www.youtube.com/watch?v='\n",
        "\n",
        "for t in train_set['youtube_id']:\n",
        "    video_url = '{}{}'.format(youtube_video_url, t)\n",
        "\n",
        "    try:\n",
        "        yt_obj = YouTube(video_url)\n",
        "    \n",
        "        filters = yt_obj.streams.filter(progressive=True, file_extension='mp4')\n",
        "    \n",
        "        # download the highest quality video\n",
        "        filters.get_highest_resolution().download(output_path='/content/random_videos')\n",
        "    except Exception as e:\n",
        "        print(e)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqXXiIoYHPzI"
      },
      "source": [
        "!zip -r random_videos.zip random_videos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmgm5YRFeGV5"
      },
      "source": [
        "model = models.video.r3d_18(pretrained=True)\n",
        "\n",
        "num_classes = 2 # is jumping jack or not\n",
        "class_names = ['Jumping Jack', 'Other']\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "model.fc = nn.Linear(512, num_classes)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/Colab_Notebooks/classfier-3d-4.pt'))\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6mfDUgAisTi"
      },
      "source": [
        "transforms = album.Compose([album.Resize(320, 320, always_apply=True)])\n",
        "\n",
        "VIDEO_PATH = '/content/drive/MyDrive/UCF12/'\n",
        "jumping_jacks = glob.glob(os.path.join(VIDEO_PATH, '*/*.avi')) # for ucf11 dataset\n",
        "random_videos = glob.glob(os.path.join(VIDEO_PATH, '*/*/*.mpg')) # for ucf101 jumping jacks\n",
        "video_files = jumping_jacks + random_videos\n",
        "\n",
        "for i in range(3):\n",
        "    random.shuffle(video_files) # randomize order for training"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rx3UW1TDsVzD"
      },
      "source": [
        "for i, video in enumerate(video_files):\n",
        "    labels = video.split('/')[5]\n",
        "    if labels == 'jumping_jack':\n",
        "        labels = torch.Tensor([0])\n",
        "    else:\n",
        "        labels = torch.Tensor([1])\n",
        "\n",
        "    print('{} {}'.format(video, labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sxa_yjwVq7Nh"
      },
      "source": [
        "video_frames = []\n",
        "clip_length = 16\n",
        "\n",
        "running_loss = 0\n",
        "model.train()\n",
        "\n",
        "for i, video in enumerate(video_files):\n",
        "    cap = cv2.VideoCapture(video)\n",
        "\n",
        "    while cap.isOpened() == True:\n",
        "        ret, frame = cap.read()\n",
        "\n",
        "        if ret == True:\n",
        "            image = frame.copy()\n",
        "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            frame = transforms(image=frame)['image']\n",
        "\n",
        "            video_frames.append(frame)\n",
        "\n",
        "            if len(video_frames) == clip_length:\n",
        "                inputs = np.array(video_frames)\n",
        "                # add an extra dimension        \n",
        "                inputs = np.expand_dims(inputs, axis=0)\n",
        "                # transpose to get [1, 3, num_clips, height, width]\n",
        "                inputs = np.transpose(inputs, (0, 4, 1, 2, 3))\n",
        "                # convert the frames to tensor\n",
        "                inputs = torch.tensor(inputs, dtype=torch.float32)\n",
        "                inputs = inputs.to(device)\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                outputs = model.forward(inputs)\n",
        "                labels = video.split('/')[5]\n",
        "\n",
        "                if labels == 'jumping_jack':\n",
        "                    labels = torch.Tensor([0])\n",
        "                else:\n",
        "                    labels = torch.Tensor([1])\n",
        "\n",
        "                labels = labels.long().to(device)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                running_loss += loss.item()\n",
        "                video_frames.clear()\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    video_frames.clear()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJwwpm01zPfK"
      },
      "source": [
        "torch.save(model.state_dict(), '/content/drive/MyDrive/Colab_Notebooks/classfier-3d-7.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2QIOvKfyrpa"
      },
      "source": [
        "!cp /content/drive/MyDrive/EE381K/*.zip .\n",
        "!unzip jumping_jack_videos.zip\n",
        "!unzip random_videos.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUv0IubVLJKS"
      },
      "source": [
        "jumping_jacks = glob.glob(os.path.join('/content/jumping_jack_videos', '*.mp4')) # from kinetics600 jumping jacks videos\n",
        "random_videos = glob.glob(os.path.join('/content/random_videos', '*.mp4')) # from kineitcs600 non jumping jacks videos\n",
        "video_files = jumping_jacks + random_videos\n",
        "\n",
        "for i in range(3):\n",
        "    random.shuffle(video_files) # randomize order for testing\n",
        "  \n",
        "video_files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Bj5oxDOp9WJ"
      },
      "source": [
        "video_frames = []\n",
        "clip_length = 16\n",
        "\n",
        "jj_correct = 0\n",
        "jj_total = 0\n",
        "notjj_correct = 0\n",
        "notjj_total = 0\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, video in enumerate(video_files):\n",
        "        cap = cv2.VideoCapture(video)\n",
        "\n",
        "        while cap.isOpened() == True:\n",
        "            ret, frame = cap.read()\n",
        "\n",
        "            if ret == True:\n",
        "                image = frame.copy()\n",
        "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "                frame = transforms(image=frame)['image']\n",
        "\n",
        "                video_frames.append(frame)\n",
        "\n",
        "                if len(video_frames) == clip_length:\n",
        "                    inputs = np.array(video_frames)\n",
        "                    # add an extra dimension        \n",
        "                    inputs = np.expand_dims(inputs, axis=0)\n",
        "                    # transpose to get [1, 3, num_clips, height, width]\n",
        "                    inputs = np.transpose(inputs, (0, 4, 1, 2, 3))\n",
        "                    # convert the frames to tensor\n",
        "                    inputs = torch.tensor(inputs, dtype=torch.float32)\n",
        "                    inputs = inputs.to(device)\n",
        "\n",
        "                    # forward pass to get the predictions\n",
        "                    outputs = model.forward(inputs)\n",
        "                    _, prediction = torch.max(outputs.data, 1)\n",
        "                    labels = video.split('/')[2]\n",
        "\n",
        "                    if labels == 'jumping_jack_videos':\n",
        "                        labels = torch.Tensor([0])\n",
        "                        jj_total += 1\n",
        "                    else:\n",
        "                        labels = torch.Tensor([1])\n",
        "                        notjj_total += 1\n",
        "\n",
        "                    if labels.item() == prediction.item():\n",
        "                        if labels.item() == 0:\n",
        "                            jj_correct += 1\n",
        "                        else:\n",
        "                            notjj_correct += 1\n",
        "\n",
        "                    video_frames.clear()\n",
        "            else:\n",
        "                break\n",
        "\n",
        "        video_frames.clear()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p__L6WKkF9vi"
      },
      "source": [
        "print('Jumping jacks percent correct: {}%'.format(jj_correct / jj_total * 100))\n",
        "print('Non-jumping jacks percent correct: {}%'.format(notjj_correct / notjj_total * 100))\n",
        "print('Total correct: {}%'.format((jj_correct + notjj_correct) / (jj_total + notjj_total) * 100))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}