{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"main.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1jqIkzYNOsy27Mip2Esyiy8492SECxBdC","authorship_tag":"ABX9TyOJmmlw5vpVCxqR4pZWFP9t"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"enF_WApSBMyW"},"source":["Program that counts the number of jumping jacks in a given video"]},{"cell_type":"code","metadata":{"id":"-rWaYYjqBdTx"},"source":["!cp \"/content/drive/MyDrive/cv2_gpu/cv2.cpython-37m-x86_64-linux-gnu.so\" ."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DMWllBmBafGX","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1619973823093,"user_tz":300,"elapsed":5692,"user":{"displayName":"Lucy W Zheng","photoUrl":"","userId":"04240352055010535427"}},"outputId":"7eedebd9-fe2c-4f07-83a0-709990858ae7"},"source":["import os\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","from PIL import Image\n","from torchvision import models, transforms, datasets\n","from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n","from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n","import cv2\n","from google.colab.patches import cv2_imshow\n","import os\n","from imutils import paths\n","import scipy.io\n","import pandas as pd\n","import csv\n","import matplotlib\n","import matplotlib.pyplot as plt\n","cv2.__version__"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'4.5.2-dev'"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"00_pirNwdeps","executionInfo":{"status":"ok","timestamp":1619974113812,"user_tz":300,"elapsed":276,"user":{"displayName":"Lucy W Zheng","photoUrl":"","userId":"04240352055010535427"}},"outputId":"d2339ec3-1169-4529-8119-1bf8fdff62f6"},"source":["if torch.cuda.is_available():\n","  device = torch.device('cuda:0')\n","else:\n","  device = torch.device('cpu')\n","  \n","print(device)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["cuda:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BjyFIlHDdwhx"},"source":["MASK_RCNN_PATH = '/content/drive/MyDrive/Colab_Notebooks/mask_rcnn.pt'\n","CLASSIFIER_PATH = '/content/drive/MyDrive/Colab_Notebooks/classfier-3d-6.pt'\n","OPEN_POSE_PROTO = '/content/drive/MyDrive/OpenPose/pose_deploy_linevec_faster_4_stages.prototxt'\n","OPEN_POSE_MODEL = '/content/drive/MyDrive/OpenPose/pose_iter_160000.caffemodel'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JNqYlFb-akrU"},"source":["mask_rcnn = models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n","in_features = mask_rcnn.roi_heads.box_predictor.cls_score.in_features\n","mask_rcnn.roi_heads.box_predictor = FastRCNNPredictor(in_features, 2)\n","in_features_mask = mask_rcnn.roi_heads.mask_predictor.conv5_mask.in_channels\n","hidden_layer = 256\n","mask_rcnn.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask, hidden_layer, 2)\n","mask_rcnn.load_state_dict(torch.load(MASK_RCNN_PATH))\n","\n","classifier = models.video.r3d_18(pretrained=True)\n","classifier.fc = nn.Linear(512, 2)\n","classifier.load_state_dict(torch.load(CLASSIFIER_PATH))\n","\n","pose_rcnn = cv2.dnn.readNetFromCaffe(OPEN_POSE_PROTO, OPEN_POSE_MODEL)\n","pose_rcnn.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n","pose_rcnn.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J3ePZEael__Q"},"source":["edges = [\n","    (0, 1), (1, 2), (1, 5), (2, 3), (3, 4), (5, 6),\n","    (6, 7), (8, 9), (9, 10), (11, 12), (12, 13), (8, 11),\n","    (2, 8), (5, 11)\n","]\n","\n","def draw_keypoints(keypoints, image):       \n","    for ie, e in enumerate(edges):\n","        # get different colors for the edges\n","        rgb = matplotlib.colors.hsv_to_rgb([\n","            ie/float(len(edges)), 1.0, 1.0\n","        ])\n","        rgb = rgb*255\n","        point1 = e[0]\n","        point2 = e[1]\n","        # join the keypoint pairs to draw the skeletal structure\n","        cv2.line(image, (keypoints[point1][0], keypoints[point1][1]),\n","                (keypoints[point2][0], keypoints[point2][1]),\n","                tuple(rgb), 5, lineType=cv2.LINE_AA)\n","    \n","    return image\n","\n","\n","def extract_points(frame, outputs):\n","    H = outputs.shape[1]\n","    W = outputs.shape[2]\n","    height = frame.shape[0]\n","    width = frame.shape[1]\n","\n","    # Empty list to store the detected keypoints\n","    points = []\n","\n","    for i in range(14):\n","        # confidence map of corresponding body's part.\n","        probMap = outputs[0, i, :, :]\n","\n","        # Find global maxima of the probMap.\n","        minVal, prob, minLoc, point = cv2.minMaxLoc(probMap)\n","\n","        # Scale the point to fit on the original image\n","        x = (point[0] * width) / W\n","        y = (point[1] * height) / H\n","        if prob > 0.10 :\n","            # Add the point to the list if the probability is greater than the threshold\n","            points.append((int(x), int(y)))\n","\n","    return points\n","\n","'''\n","Returns true if human looks like this:\n","   /   \\\n","   \\ O /\n","    \\_/\n","     V\n","    / \\\n","   /   \\\n","'''\n","def check_jumping_jack(keypoints):\n","    top_head = keypoints[1]\n","    left_elbow = keypoints[3]\n","    right_elbow = keypoints[6]\n","    left_hip = keypoints[8]\n","    right_hip = keypoints[11]\n","    left_foot = keypoints[10]\n","    right_foot = keypoints[13]\n","\n","    if top_head[1] > left_elbow[1] and top_head[1] > right_elbow[1] and left_foot[0] < left_hip[0] and right_foot[0] > right_hip[0]:\n","        return True\n","\n","    return False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4_wKz8-YfjCE"},"source":["# using pose cnn, check if left wrist and right wrist is above head level\n","# and falls to hip joint/ below elbows\n","# count as 1 jumping jack each time action is repeated\n","# also needs to see if feet y value changes (jump) and x value changes (split)\n","VIDEO_PATH = '/content/test_video.mp4'\n","\n","mask_rcnn.to(device)\n","classifier.to(device)\n","\n","action_classes = ['Jumping Jack', 'Other']\n","video_arr = []\n","current_clip = []\n","raw_frames = []\n","\n","complete_jj = False\n","\n","mask_rcnn.eval()\n","classifier.eval()\n","\n","counter = 0\n","cap = cv2.VideoCapture(VIDEO_PATH)\n","size = None\n","\n","while cap.isOpened():\n","    ret, frame = cap.read()\n","\n","    if ret == True:\n","        size = (frame.shape[1], frame.shape[0]) # width, height\n","        inputs = np.transpose(frame, (2, 0, 1))\n","        inputs = inputs.astype(float)/255\n","        inputs = torch.from_numpy(inputs)\n","\n","        inputs = torch.unsqueeze(inputs, 0).float()\n","        inputs = inputs.to(device)\n","        outputs = mask_rcnn(inputs)\n","\n","        # if no human detected, skip frame\n","        if list(outputs[0]['scores'].size())[0] == 0:\n","            frame = cv2.rectangle(frame, (0, 0), (int(size[0] / 2), int(size[1] / 10)), (0, 0, 0), -1)\n","            frame = cv2.putText(frame, 'Counter:{}'.format(counter), (20, int(size[1] / 10) - 20), cv2.FONT_HERSHEY_DUPLEX,\n","                                2, (255, 255, 255), 2, cv2.LINE_AA)\n","            video_arr.append(frame)\n","        else:\n","            found_human = outputs[0]['scores'][0].item() > 0.5\n","            current_clip.append(frame)\n","\n","            if found_human == True and len(current_clip) == 16:\n","                # prepare for 3d classifier\n","                inputs_classifier = np.array(current_clip)\n","                # add an extra dimension        \n","                inputs_classifier = np.expand_dims(inputs_classifier, axis=0)\n","                # transpose to get [1, 3, num_clips, height, width]\n","                inputs_classifier = np.transpose(inputs_classifier, (0, 4, 1, 2, 3))\n","                # convert the frames to tensor\n","                inputs_classifier = torch.tensor(inputs_classifier, dtype=torch.float32)\n","                inputs_classifier = inputs_classifier.to(device)\n","\n","                outputs = classifier(inputs_classifier)\n","                _, result = torch.max(outputs.data, 1)\n","                predict_class = action_classes[result] == 'Jumping Jack'\n","                print(predict_class)\n","\n","                for f in current_clip:\n","                    inpBlob = cv2.dnn.blobFromImage(f, 1.0 / 255, (368, 368), (0, 0, 0), swapRB=False, crop=False)\n","\n","                    # Set the prepared object as the input blob of the network\n","                    pose_rcnn.setInput(inpBlob)\n","\n","                    outputs = pose_rcnn.forward()\n","                    points = extract_points(f, outputs)\n","                    \n","                    if len(points) == 14:\n","                        # check of apex of jump\n","                        check_jj = check_jumping_jack(points)\n","\n","                        if complete_jj == False and check_jj == True and predict_class:\n","                            counter += 1\n","                            complete_jj = True\n","                        else:\n","                            if complete_jj == True and check_jj == False:\n","                                complete_jj = False\n","                        f = draw_keypoints(points, f)\n","\n","                    f = cv2.rectangle(f, (0, 0), (int(size[0] / 2), int(size[1] / 10)), (0, 0, 0), -1)\n","                    f = cv2.putText(f, 'Counter:{}'.format(counter), (0, int(size[1] / 10)), cv2.FONT_HERSHEY_DUPLEX,\n","                                0.8, (255, 255, 255), 2, cv2.LINE_AA)\n","                    video_arr.append(f)\n","                \n","                current_clip.clear()\n","    else:\n","        break\n","\n","cap.release()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2RPCkDKLrAO_"},"source":["out = cv2.VideoWriter('/content/result.avi', cv2.VideoWriter_fourcc(*'DIVX'), 10, size)\n","\n","for i in range(len(video_arr)):\n","    out.write(video_arr[i])\n","out.release()"],"execution_count":null,"outputs":[]}]}